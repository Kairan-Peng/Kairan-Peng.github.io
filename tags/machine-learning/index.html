<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>标签: machine-learning | 你刚刚打开了这个博客</title><meta name="author" content="Kevin Parker"><meta name="copyright" content="Kevin Parker"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="记点笔记，以证时光">
<meta property="og:type" content="website">
<meta property="og:title" content="你刚刚打开了这个博客">
<meta property="og:url" content="http://110.42.233.207/tags/machine-learning/index.html">
<meta property="og:site_name" content="你刚刚打开了这个博客">
<meta property="og:description" content="记点笔记，以证时光">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://avatars.githubusercontent.com/u/91741133?v=4">
<meta property="article:author" content="Kevin Parker">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://avatars.githubusercontent.com/u/91741133?v=4"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://110.42.233.207/tags/machine-learning/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '标签: machine-learning',
  isPost: false,
  isHome: false,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2021-12-08 23:03:17'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://avatars.githubusercontent.com/u/91741133?v=4" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">17</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-bookmark"></i><span> 文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div></div></div></div><div class="page" id="body-wrap"><header class="not-home-page" id="page-header" style="background-image: url('/img/index_img.jpeg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">你刚刚打开了这个博客</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-bookmark"></i><span> 文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="page-site-info"><h1 id="site-title">machine-learning</h1></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/machine-learning-exp_LogisticRegression/" title="【机器学习】实践-使用Logistic回归模型来预测Breast Cancer">     <img class="post_bg" src="/machine-learning-exp_LogisticRegression/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】实践-使用Logistic回归模型来预测Breast Cancer"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-exp_LogisticRegression/" title="【机器学习】实践-使用Logistic回归模型来预测Breast Cancer">【机器学习】实践-使用Logistic回归模型来预测Breast Cancer</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-07T08:53:00.000Z" title="发表于 2021-12-07 16:53:00">2021-12-07</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/logistic-regression/">logistic-regression</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/experiment/">experiment</a></span></div><div class="content">1 数据准备直接使用sklearn包里的breast_cancer数据集。
加载数据并划分数据集：
123456789101112import pandas as pdfrom sklearn.datasets import load_breast_cancerfrom sklearn.model_selection import train_test_split# X, y = load_breast_cancer(return_X_y=True, as_frame=True)data = load_breast_cancer(as_frame=True)pd_X = data.get(&#x27;data&#x27;)pd_y = data.get(&#x27;target&#x27;)X = pd_X.valuesy = pd_y.valuesprint(&#x27;data shape: &#123;&#125;, no. positive: &#123;&#125;, no. negative: &#123;&#125;&#x27;.format(X.shape, y[y== ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/machine-learning-exp_DecisionTreeClassifier/" title="【机器学习】实践-使用决策树来预测Titanic幸存者">     <img class="post_bg" src="/machine-learning-exp_DecisionTreeClassifier/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】实践-使用决策树来预测Titanic幸存者"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-exp_DecisionTreeClassifier/" title="【机器学习】实践-使用决策树来预测Titanic幸存者">【机器学习】实践-使用决策树来预测Titanic幸存者</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-06T11:53:00.000Z" title="发表于 2021-12-06 19:53:00">2021-12-06</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/decision-tree/">decision-tree</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/experiment/">experiment</a></span></div><div class="content">1 数据准备1.1 数据集下载在kaggle上下载Titanic数据集。
1.2 读取数据并预处理12345678910111213141516171819202122232425import pandas as pdimport numpy as npfrom sklearn.model_selection import train_test_splitfrom sklearn.tree import DecisionTreeClassifierdef read_dataset(fname):    &quot;&quot;&quot;    读取数据并预处理    &quot;&quot;&quot;    # 读取数据，指定第一列为索引列    data = pd.read_csv(fname, index_col=0)    print(data.shape)    print(data.columns)    # 丢弃无用的数据    data.drop([&#x27;Name&#x27;, &#x27;Ticket&#x27;, &#x27;Cabin&#x27;], ax ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/machine-learning-exp-KNN/" title="【机器学习】实践-使用k近邻算法及其变种预测的糖尿病">     <img class="post_bg" src="/machine-learning-exp-KNN/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】实践-使用k近邻算法及其变种预测的糖尿病"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-exp-KNN/" title="【机器学习】实践-使用k近邻算法及其变种预测的糖尿病">【机器学习】实践-使用k近邻算法及其变种预测的糖尿病</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-05T13:44:01.000Z" title="发表于 2021-12-05 21:44:01">2021-12-05</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/knn/">knn</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/experiment/">experiment</a></span></div><div class="content">1 数据准备1.1 数据集下载在kaggle上下载糖尿病数据集。
1.2 划分训练集和测试集1234567891011from sklearn.model_selection import train_test_splitimport pandas as pdfrom sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier# 划分数据集data = pd.read_csv(&#x27;../Datasets/diabetes.csv&#x27;)# print(data.shape)# print(dataset.head())X = data.iloc[:, 0:8]Y = data.iloc[:, 8]X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)X_train.shape, Y_train.shape
看一下数据集的形状
((614, 8), (614,))
2 模型训练2.1 载入模型并训练使 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/machine-learning-SupportVectorMachine/" title="【机器学习】支持向量机SVM">     <img class="post_bg" src="/machine-learning-SupportVectorMachine/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】支持向量机SVM"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-SupportVectorMachine/" title="【机器学习】支持向量机SVM">【机器学习】支持向量机SVM</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-04T06:11:25.000Z" title="发表于 2021-12-04 14:11:25">2021-12-04</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/svm/">svm</a></span></div><div class="content">1 简介 支持向量机（Support Vector Machine. SVM）是二类分类模型。它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机。

与感知机的区别：感知机的分类的超平面结果是多个的，没有给出一个最优解。

支持向量机的学习策略就是间隔最大化，可形式化为一个求解凸二次规划（convex quadratic programming）的问题，也等价于正则化的合页损失函数的最小化问题。
支持向量机的学习算法是求解凸二次规划的最优化算法。
1.1 SVM分类
线性可分支持向量机（linear support vector machine in linearly separable case ）：硬间隔最大化（hard margin maximization）。

线性支持向量机（linear supportvector machine）：训练数据近似线性可分时，通过软间隔最大化（soft margin maximization）。

非线性支持向量机（non-linear support vector machine）：当训练数据线性不可分时，通过使 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/machine-learning-MaxEntropyModel/" title="【机器学习】最大熵模型">     <img class="post_bg" src="/machine-learning-MaxEntropyModel/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】最大熵模型"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-MaxEntropyModel/" title="【机器学习】最大熵模型">【机器学习】最大熵模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-04T04:38:53.000Z" title="发表于 2021-12-04 12:38:53">2021-12-04</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/max-entropy-model/">max-entropy-model</a></span></div><div class="content">1 最大熵原理最大熵原理是一种选择随机变量统计特性最符合客观情况的准则，也称为最大信息原理。
随机量的概率分布是很难测定的，一般只能测得其各种均值（如数学期望、方差等）或已知某些限定条件下的值（如峰值、取值个数等），符合测得这些值的分布可有多种、以至无穷多种，通常，其中有一种分布的熵最大。 选用这种具有最大熵的分布作为该随机变量的分布，是一种有效的处理方法和准则。
这种方法虽有一定的主观性，但可以认为是最符合客观情况的一种选择。
2 最大熵模型2.1 简介最大熵模型（Maximum Entropy Model）由最大熵原理推导实现。学习概率模型时，在满足约束条件的模型集合中选取熵最大的模型。
假设离散随机变量 $X$ 的概率分布是 $P(X)$ ，变量 $X$ 的熵为：
$H(P) = -\sum_x P(x)\log P(x)$ ，
有：$0 \le H(P) \le \log |X|$ （ $|X|$ 是 $X$ 的取值个数， $X$ 均匀分布时右边等号成立）。
$\tilde P$ 代表经验概率，即从训练集中统计得到的概率。
2.2 模型2.2.1 模型假设给定数据集 $ T=\ ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/machine-learning-LogisticRegression/" title="【机器学习】Logistic回归">     <img class="post_bg" src="/machine-learning-LogisticRegression/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】Logistic回归"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-LogisticRegression/" title="【机器学习】Logistic回归">【机器学习】Logistic回归</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-03T01:54:00.000Z" title="发表于 2021-12-03 09:54:00">2021-12-03</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/logistic-regression/">logistic-regression</a></span></div><div class="content">1 概述Logistic Regression，又称逻辑斯蒂克回归、逻辑回归、对数几率回归。
Logistic分布函数： $F(z) = P(Z \le z) = \frac{1}{1+e^{-z}}$
密度函数和分布函数如图：
 
逻辑回归（Logistic Regression）与线性回归（Linear Regression）都是一种广义线性模型（generalized linear model）。逻辑回归假设因变量 $y$ 服从伯努利分布，而线性回归假设因变量 $y$ 服从高斯分布。
2 模型2.1 回归模型 Logistic是一种二分类模型，由条件概率分布 $P(Y|X)$ 表示，这里，$X$ 取值为实数， $Y$ 取值为 $\{0,1\}$ ，二项式Logistic回归按照如下模型，令前面的 $z = w·x + b$ ，有：
$P(Y=1|x) = \frac{1}{1+e^{-z}} = \frac{1}{1+e^{-(w·x+b)}} = \frac{\exp(w·x+b)}{1+\exp(w·x+b)}$

当 $w·x + b \gg 0$ 时， $P(Y=1|x) ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/machine-learning-Decision-Tree/" title="【机器学习】决策树">     <img class="post_bg" src="/machine-learning-Decision-Tree/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】决策树"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-Decision-Tree/" title="【机器学习】决策树">【机器学习】决策树</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-11-28T11:17:57.000Z" title="发表于 2021-11-28 19:17:57">2021-11-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/decision-tree/">decision-tree</a></span></div><div class="content">1 简介1.1 什么是决策树决策树（Decision Tree）是一种描述对实例进行分类的树状结构。

决策节点：代表一个问题或者决策。
有向边：代表决策节点的不同取值。
叶子节点：代表可能的分类结果。


在沿着决策树从上到下的遍历过程中，在每个结点都有一个测试。对每个结点上问题的不同测试输出导致不同的分枝，最后会达到一个叶子结点。这一过程就是利用决策树进行分类的过程，利用若干个变量来判断属性的类别。
决策树学习本质上是从训练数据集中归纳出一组分类规则，与训练数据集不相矛盾的决策树。
能对训练数据进行正确分类的决策树可能有多个，也可能 一个也没有。
需要的是一个与训练数据矛盾较小的决策树，同时具有很好的泛化能力。 
决策树技术发现数据模式和规则的核心是归纳算法。
1.2 决策树与条件概率分布决策树表示给定特征条件下类的条件概率分布，决策树的一条路径对应于划分中的一个单元，决策树所表示的条件概率分布由各个单元给定条件下类的条件概率分布组成。（条件概率分布定义在特征空间的一个划分(partition)上，将特征空间划分为互不相交的单元(cell)或区域(region)，并在每个单元定义一 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/machine-learning-Naive-Bayesian-Model/" title="【机器学习】朴素贝叶斯">     <img class="post_bg" src="/machine-learning-Naive-Bayesian-Model/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】朴素贝叶斯"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-Naive-Bayesian-Model/" title="【机器学习】朴素贝叶斯">【机器学习】朴素贝叶斯</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-11-28T07:38:49.000Z" title="发表于 2021-11-28 15:38:49">2021-11-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/nbm/">nbm</a></span></div><div class="content">1 简介 朴素贝叶斯法（Naive Bayesian Model，NBM）是基于贝叶斯定理与特征条件独立假设的分类方法。
对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率分布；然后基于此模型，对给定的输入，利用贝叶斯定理求出后验概率最大的输出。
朴素贝叶斯方法实现简单，学习与预测的效率都很高，是一种常用方法。
2 贝叶斯定理
已知某条件概率 $P(A|B)$ ，如何得到两个事件交换后的概率 $P(B|A)$ ：
  $P(B|A) = \frac{P(AB)}{P(A)} = \frac{P(A|B)P(B)}{P(A)}$

全概率公式：
  $P(A) = \sum_{i=1}^n P(B_i) P(A|B_i)$


3 朴素贝叶斯定义设训练数据集 $ T=\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\} $ 由$P(X,Y)$ 独立同分布产生，其中 $ x_i\in X\subseteq R^n $ 为实例特征向量， $ y_i\in Y=\{c_1,c_2,..,c_k\} $ 为实例类别， $ i=1,2,…,N $ 。
对于新的 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/machine-learning-K-Nearest-Neighbors/" title="【机器学习】k近邻算法">     <img class="post_bg" src="/machine-learning-K-Nearest-Neighbors/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】k近邻算法"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-K-Nearest-Neighbors/" title="【机器学习】k近邻算法">【机器学习】k近邻算法</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-11-27T12:05:35.000Z" title="发表于 2021-11-27 20:05:35">2021-11-27</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/knn/">knn</a></span></div><div class="content">1 k近邻算法1.1 算法简介k近邻（K-Nearest Neighbors, KNN）法是一种基本分类与回归方法，支持多分类，于1968年由Cover和Hart提出。

输入：实例的特征空间向量。

输出：实例的类别。

算法思想：分类时，对新的实例，根据其k个最近邻的训练实例的类别，通过多数表决等方式进行预测。k近邻法实际上利用训练数据集对特征向量空间进行划分，并作为其分类的“模型”。

优点：

精度高
对异常值不敏感
无数据输入假定


缺点：
计算复杂度高
空间复杂度高


适用范围：数值型、标称型

k值的选择、距离度量方法及分类决策规则是k近邻法的三个要素。
1.2 算法原理存在一个样本数据集合，也称作训练样本集 $X$ ，并且样本集中每个数据 $x_i$ 都存在标签 $y_i$ ，即样本集中每个数据与所属分类的对应关系。
输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。
一般来说，只选择样本数据集中前N个最相似的数据。k一般不大于20，最后，选择k个中出现次数最多的分类，作为新数据的分类 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/machine-learning-Perceptron/" title="【机器学习】感知机">     <img class="post_bg" src="/machine-learning-Perceptron/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】感知机"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-Perceptron/" title="【机器学习】感知机">【机器学习】感知机</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-11-27T07:07:14.000Z" title="发表于 2021-11-27 15:07:14">2021-11-27</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/perceptron/">perceptron</a></span></div><div class="content">1 简介感知机（Perceptron）是一个二分类的判别模型， 它在1957年由Rosenblatt提出，是神经网络与支持向量机的基础。

输入：实例的特征向量
输出：实例的类别，取+1和-1

感知机对应于输入空间中将实例划分为正负两类的分离超平面。 
导入基于误分类的损失函数，利用梯度下降法对损失函数进行极小化。
感知机学习算法具有简单而易于实现的优点，分为原始形式和对偶形式。
2 模型2.1 介绍假设输入空间（特征空间）是 $ X\subseteq R^n $ ，输出空间是 $ Y=\{+1,-1\} $ 
输入 $ x\in X $ 表示实例的特征向量，对应输入空间的点，输出 $ y\in Y $ 表示实例的类别，由输入空间到输出空间到函数为：

f(x)=sign(w·x+b)其中 $ w $ 为 $ n $ 维的权值向量， $ w·x $ 为内积（对应维乘积之和）， $ b $ 为偏置， $ sign $ 为符号函数

sign(x) =
\begin{cases}
+1, & \text{x $\ge$ 0}  \\\\
-1, & \text{x $\lt$ 0}
\e ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/tags/machine-learning/page/2/">2</a><a class="extend next" rel="next" href="/tags/machine-learning/page/2/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://avatars.githubusercontent.com/u/91741133?v=4" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Kevin Parker</div><div class="author-info__description">一只菜鸟的学习笔记</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">17</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Kairan-Peng"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Kairan-Peng" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:peng.kairan@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/machine-learning-exp_LogisticRegression/" title="【机器学习】实践-使用Logistic回归模型来预测Breast Cancer"><img src="/machine-learning-exp_LogisticRegression/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】实践-使用Logistic回归模型来预测Breast Cancer"/></a><div class="content"><a class="title" href="/machine-learning-exp_LogisticRegression/" title="【机器学习】实践-使用Logistic回归模型来预测Breast Cancer">【机器学习】实践-使用Logistic回归模型来预测Breast Cancer</a><time datetime="2021-12-07T08:53:00.000Z" title="发表于 2021-12-07 16:53:00">2021-12-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/machine-learning-exp_DecisionTreeClassifier/" title="【机器学习】实践-使用决策树来预测Titanic幸存者"><img src="/machine-learning-exp_DecisionTreeClassifier/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】实践-使用决策树来预测Titanic幸存者"/></a><div class="content"><a class="title" href="/machine-learning-exp_DecisionTreeClassifier/" title="【机器学习】实践-使用决策树来预测Titanic幸存者">【机器学习】实践-使用决策树来预测Titanic幸存者</a><time datetime="2021-12-06T11:53:00.000Z" title="发表于 2021-12-06 19:53:00">2021-12-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/machine-learning-exp-KNN/" title="【机器学习】实践-使用k近邻算法及其变种预测的糖尿病"><img src="/machine-learning-exp-KNN/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】实践-使用k近邻算法及其变种预测的糖尿病"/></a><div class="content"><a class="title" href="/machine-learning-exp-KNN/" title="【机器学习】实践-使用k近邻算法及其变种预测的糖尿病">【机器学习】实践-使用k近邻算法及其变种预测的糖尿病</a><time datetime="2021-12-05T13:44:01.000Z" title="发表于 2021-12-05 21:44:01">2021-12-05</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/C/"><span class="card-category-list-name">C++</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/computer-vision/"><span class="card-category-list-name">computer-vision</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/help/"><span class="card-category-list-name">help</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/machine-learning/"><span class="card-category-list-name">machine-learning</span><span class="card-category-list-count">11</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/C/" style="font-size: 1.15em; color: rgb(173, 3, 175)">C++</a><a href="/tags/computer-vision/" style="font-size: 1.25em; color: rgb(148, 155, 3)">computer-vision</a><a href="/tags/frp/" style="font-size: 1.15em; color: rgb(15, 132, 156)">frp</a><a href="/tags/remote-desktop/" style="font-size: 1.15em; color: rgb(125, 114, 179)">remote-desktop</a><a href="/tags/hello-world/" style="font-size: 1.15em; color: rgb(85, 167, 29)">hello-world</a><a href="/tags/hexo/" style="font-size: 1.15em; color: rgb(143, 36, 108)">hexo</a><a href="/tags/blog/" style="font-size: 1.15em; color: rgb(59, 22, 110)">blog</a><a href="/tags/machine-learning/" style="font-size: 1.45em; color: rgb(119, 175, 141)">machine-learning</a><a href="/tags/decision-tree/" style="font-size: 1.25em; color: rgb(76, 23, 170)">decision-tree</a><a href="/tags/knn/" style="font-size: 1.25em; color: rgb(128, 28, 139)">knn</a><a href="/tags/nbm/" style="font-size: 1.15em; color: rgb(188, 9, 13)">nbm</a><a href="/tags/perceptron/" style="font-size: 1.15em; color: rgb(83, 82, 150)">perceptron</a><a href="/tags/logistic-regression/" style="font-size: 1.25em; color: rgb(43, 74, 37)">logistic-regression</a><a href="/tags/svm/" style="font-size: 1.15em; color: rgb(68, 185, 149)">svm</a><a href="/tags/experiment/" style="font-size: 1.35em; color: rgb(192, 132, 141)">experiment</a><a href="/tags/max-entropy-model/" style="font-size: 1.15em; color: rgb(130, 83, 107)">max-entropy-model</a></div></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">17</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2021-12-08T15:03:17.608Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Kevin Parker</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="icp"><a target="_blank" rel="noopener" href="http://beian.miit.gov.cn/"><span>浙ICP备2021037349号-1</span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>