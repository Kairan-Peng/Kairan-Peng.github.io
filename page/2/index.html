<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>你刚刚打开了这个博客 - 菜鸟学习笔记</title><meta name="author" content="Kevin Parker"><meta name="copyright" content="Kevin Parker"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="记点笔记，以证时光">
<meta property="og:type" content="website">
<meta property="og:title" content="你刚刚打开了这个博客">
<meta property="og:url" content="http://110.42.233.207/page/2/index.html">
<meta property="og:site_name" content="你刚刚打开了这个博客">
<meta property="og:description" content="记点笔记，以证时光">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://avatars.githubusercontent.com/u/91741133?v=4">
<meta property="article:author" content="Kevin Parker">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://avatars.githubusercontent.com/u/91741133?v=4"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://110.42.233.207/page/2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '你刚刚打开了这个博客',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-02-27 20:55:53'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://avatars.githubusercontent.com/u/91741133?v=4" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">26</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">28</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-bookmark"></i><span> 文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/index_img.jpeg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">你刚刚打开了这个博客</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-bookmark"></i><span> 文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">你刚刚打开了这个博客</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/Kairan-Peng" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:peng.kairan@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/machine-learning-exp_DecisionTreeClassifier/" title="【机器学习】实践-使用决策树来预测Titanic幸存者">     <img class="post_bg" src="/machine-learning-exp_DecisionTreeClassifier/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】实践-使用决策树来预测Titanic幸存者"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-exp_DecisionTreeClassifier/" title="【机器学习】实践-使用决策树来预测Titanic幸存者">【机器学习】实践-使用决策树来预测Titanic幸存者</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-06T11:53:00.000Z" title="发表于 2021-12-06 19:53:00">2021-12-06</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/decision-tree/">decision-tree</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/experiment/">experiment</a></span></div><div class="content">1 数据准备1.1 数据集下载在kaggle上下载Titanic数据集。
1.2 读取数据并预处理12345678910111213141516171819202122232425import pandas as pdimport numpy as npfrom sklearn.model_selection import train_test_splitfrom sklearn.tree import DecisionTreeClassifierdef read_dataset(fname):    &quot;&quot;&quot;    读取数据并预处理    &quot;&quot;&quot;    # 读取数据，指定第一列为索引列    data = pd.read_csv(fname, index_col=0)    print(data.shape)    print(data.columns)    # 丢弃无用的数据    data.drop([&#x27;Name&#x27;, &#x27;Ticket&#x27;, &#x27;Cabin&#x27;], ax ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/machine-learning-exp-KNN/" title="【机器学习】实践-使用k近邻算法及其变种预测的糖尿病">     <img class="post_bg" src="/machine-learning-exp-KNN/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】实践-使用k近邻算法及其变种预测的糖尿病"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-exp-KNN/" title="【机器学习】实践-使用k近邻算法及其变种预测的糖尿病">【机器学习】实践-使用k近邻算法及其变种预测的糖尿病</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-05T13:44:01.000Z" title="发表于 2021-12-05 21:44:01">2021-12-05</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/knn/">knn</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/experiment/">experiment</a></span></div><div class="content">1 数据准备1.1 数据集下载在kaggle上下载糖尿病数据集。
1.2 划分训练集和测试集1234567891011from sklearn.model_selection import train_test_splitimport pandas as pdfrom sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier# 划分数据集data = pd.read_csv(&#x27;../Datasets/diabetes.csv&#x27;)# print(data.shape)# print(dataset.head())X = data.iloc[:, 0:8]Y = data.iloc[:, 8]X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)X_train.shape, Y_train.shape
看一下数据集的形状
((614, 8), (614,))
2 模型训练2.1 载入模型并训练使 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/machine-learning-SupportVectorMachine/" title="【机器学习】支持向量机SVM">     <img class="post_bg" src="/machine-learning-SupportVectorMachine/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】支持向量机SVM"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-SupportVectorMachine/" title="【机器学习】支持向量机SVM">【机器学习】支持向量机SVM</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-04T06:11:25.000Z" title="发表于 2021-12-04 14:11:25">2021-12-04</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/svm/">svm</a></span></div><div class="content">1 简介 支持向量机（Support Vector Machine. SVM）是二类分类模型。它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机。

与感知机的区别：感知机的分类的超平面结果是多个的，没有给出一个最优解。

支持向量机的学习策略就是间隔最大化，可形式化为一个求解凸二次规划（convex quadratic programming）的问题，也等价于正则化的合页损失函数的最小化问题。
支持向量机的学习算法是求解凸二次规划的最优化算法。
1.1 SVM分类
线性可分支持向量机（linear support vector machine in linearly separable case ）：硬间隔最大化（hard margin maximization）。

线性支持向量机（linear supportvector machine）：训练数据近似线性可分时，通过软间隔最大化（soft margin maximization）。

非线性支持向量机（non-linear support vector machine）：当训练数据线性不可分时，通过使 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/machine-learning-MaxEntropyModel/" title="【机器学习】最大熵模型">     <img class="post_bg" src="/machine-learning-MaxEntropyModel/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】最大熵模型"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-MaxEntropyModel/" title="【机器学习】最大熵模型">【机器学习】最大熵模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-04T04:38:53.000Z" title="发表于 2021-12-04 12:38:53">2021-12-04</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/max-entropy-model/">max-entropy-model</a></span></div><div class="content">1 最大熵原理最大熵原理是一种选择随机变量统计特性最符合客观情况的准则，也称为最大信息原理。
随机量的概率分布是很难测定的，一般只能测得其各种均值（如数学期望、方差等）或已知某些限定条件下的值（如峰值、取值个数等），符合测得这些值的分布可有多种、以至无穷多种，通常，其中有一种分布的熵最大。 选用这种具有最大熵的分布作为该随机变量的分布，是一种有效的处理方法和准则。
这种方法虽有一定的主观性，但可以认为是最符合客观情况的一种选择。
2 最大熵模型2.1 简介最大熵模型（Maximum Entropy Model）由最大熵原理推导实现。学习概率模型时，在满足约束条件的模型集合中选取熵最大的模型。
假设离散随机变量 $X$ 的概率分布是 $P(X)$ ，变量 $X$ 的熵为：
$H(P) = -\sum_x P(x)\log P(x)$ ，
有：$0 \le H(P) \le \log |X|$ （ $|X|$ 是 $X$ 的取值个数， $X$ 均匀分布时右边等号成立）。
$\tilde P$ 代表经验概率，即从训练集中统计得到的概率。
2.2 模型2.2.1 模型假设给定数据集 $ T=\ ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/machine-learning-LogisticRegression/" title="【机器学习】Logistic回归">     <img class="post_bg" src="/machine-learning-LogisticRegression/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】Logistic回归"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-LogisticRegression/" title="【机器学习】Logistic回归">【机器学习】Logistic回归</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-03T01:54:00.000Z" title="发表于 2021-12-03 09:54:00">2021-12-03</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/logistic-regression/">logistic-regression</a></span></div><div class="content">1 概述Logistic Regression，又称逻辑斯蒂克回归、逻辑回归、对数几率回归。
Logistic分布函数： $F(z) = P(Z \le z) = \frac{1}{1+e^{-z}}$
密度函数和分布函数如图：
 
逻辑回归（Logistic Regression）与线性回归（Linear Regression）都是一种广义线性模型（generalized linear model）。逻辑回归假设因变量 $y$ 服从伯努利分布，而线性回归假设因变量 $y$ 服从高斯分布。
2 模型2.1 回归模型 Logistic是一种二分类模型，由条件概率分布 $P(Y|X)$ 表示，这里，$X$ 取值为实数， $Y$ 取值为 $\{0,1\}$ ，二项式Logistic回归按照如下模型，令前面的 $z = w·x + b$ ，有：
$P(Y=1|x) = \frac{1}{1+e^{-z}} = \frac{1}{1+e^{-(w·x+b)}} = \frac{\exp(w·x+b)}{1+\exp(w·x+b)}$

当 $w·x + b \gg 0$ 时， $P(Y=1|x) ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/cv-ImageProcessingExperiment/" title="【计算机视觉】图像处理实验-高斯噪声，椒盐噪声，均值滤波，高斯滤波，中值滤波">     <img class="post_bg" src="/cv-ImageProcessingExperiment/trump.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【计算机视觉】图像处理实验-高斯噪声，椒盐噪声，均值滤波，高斯滤波，中值滤波"></a></div><div class="recent-post-info"><a class="article-title" href="/cv-ImageProcessingExperiment/" title="【计算机视觉】图像处理实验-高斯噪声，椒盐噪声，均值滤波，高斯滤波，中值滤波">【计算机视觉】图像处理实验-高斯噪声，椒盐噪声，均值滤波，高斯滤波，中值滤波</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-02T05:01:01.000Z" title="发表于 2021-12-02 13:01:01">2021-12-02</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/computer-vision/">computer-vision</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/computer-vision/">computer-vision</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/exp/">exp</a></span></div><div class="content">1 实验目标
选择一幅灰度图像，分别添加高斯噪声和椒盐噪声。
分别用均值滤波、高斯滤波和中值滤波器对两类噪声图像去噪。
分析、比较各滤波器对各类噪声的去噪效果。

2 实验步骤2.1 将彩色原图转换成灰度图123456789101112131415161718192021import cv2import numpy as npfrom  matplotlib import pyplot as plt%matplotlib inlineimg_origin = cv2.imread(&#x27;trump_origin.jpeg&#x27;)img = cv2.cvtColor(img_origin,cv2.COLOR_RGB2GRAY)cv2.imwrite(&#x27;trump.jpeg&#x27;,img)# plt.subplot(2,1,1)plt.title(&#x27;origin&#x27;)plt.imshow(img_origin[:,:,::-1])plt.show()# plt.subplot(2,1,2)plt.title(&#x27;gray&#x27;)p ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/cv-image-Denoising-and-Restoration/" title="【计算机视觉】图像去噪与图像复原概述">     <img class="post_bg" src="/cv-image-Denoising-and-Restoration/cv.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【计算机视觉】图像去噪与图像复原概述"></a></div><div class="recent-post-info"><a class="article-title" href="/cv-image-Denoising-and-Restoration/" title="【计算机视觉】图像去噪与图像复原概述">【计算机视觉】图像去噪与图像复原概述</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-01T09:10:16.000Z" title="发表于 2021-12-01 17:10:16">2021-12-01</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/computer-vision/">computer-vision</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/computer-vision/">computer-vision</a></span></div><div class="content">1 图像降质图像降质的分类：

噪声等形成的降质
运动引起的降质
亚采样引起的降质

2 图像增强与图像复原2.1 概述改善降质图像的方法有两类：
一类是不考虑图像降质的原因， 只将图像中感兴趣的部分加以处理或突出有用的图像特征，故改善后的图像并不一定要去逼近原图像。这一类图像改善方法称为图像增强，主要目的是要提高图像的可懂度。
另一类方法是针对图像 降质的具体原因，设法补偿降质因素，使改善后的图像尽可能地逼 近原始图像。这类方法称为图像恢复或图像复原技术。
2.2 图像增强与图像复原的关系
图像增强：旨在改善图像质量。提高图像的可懂度。更偏向主观判断，即要突出所关心的信息，满足人的视觉系统，具有好的视觉结果。
图像复原：根据图像畸变或退化的原因，进行模型化处理，将质量退化的图像重建或恢复到原始图像，即恢复退化图像的本来面目，忠实于原图像。因此必须根据一定的图像退化模型来进行图像复原。

2.3 图像增强
定义：图像增强是指按特定的需要突出一幅图像中的某些信息，同时，消弱或去除某些不需要的信息的处理方法

目的：对图像进行加工，以得到对具体应用来说视觉效果更“好”，更“有用”的图像，也 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/machine-learning-Decision-Tree/" title="【机器学习】决策树">     <img class="post_bg" src="/machine-learning-Decision-Tree/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】决策树"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-Decision-Tree/" title="【机器学习】决策树">【机器学习】决策树</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-11-28T11:17:57.000Z" title="发表于 2021-11-28 19:17:57">2021-11-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/decision-tree/">decision-tree</a></span></div><div class="content">1 简介1.1 什么是决策树决策树（Decision Tree）是一种描述对实例进行分类的树状结构。

决策节点：代表一个问题或者决策。
有向边：代表决策节点的不同取值。
叶子节点：代表可能的分类结果。


在沿着决策树从上到下的遍历过程中，在每个结点都有一个测试。对每个结点上问题的不同测试输出导致不同的分枝，最后会达到一个叶子结点。这一过程就是利用决策树进行分类的过程，利用若干个变量来判断属性的类别。
决策树学习本质上是从训练数据集中归纳出一组分类规则，与训练数据集不相矛盾的决策树。
能对训练数据进行正确分类的决策树可能有多个，也可能 一个也没有。
需要的是一个与训练数据矛盾较小的决策树，同时具有很好的泛化能力。 
决策树技术发现数据模式和规则的核心是归纳算法。
1.2 决策树与条件概率分布决策树表示给定特征条件下类的条件概率分布，决策树的一条路径对应于划分中的一个单元，决策树所表示的条件概率分布由各个单元给定条件下类的条件概率分布组成。（条件概率分布定义在特征空间的一个划分(partition)上，将特征空间划分为互不相交的单元(cell)或区域(region)，并在每个单元定义一 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/machine-learning-Naive-Bayesian-Model/" title="【机器学习】朴素贝叶斯">     <img class="post_bg" src="/machine-learning-Naive-Bayesian-Model/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】朴素贝叶斯"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-Naive-Bayesian-Model/" title="【机器学习】朴素贝叶斯">【机器学习】朴素贝叶斯</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-11-28T07:38:49.000Z" title="发表于 2021-11-28 15:38:49">2021-11-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/nbm/">nbm</a></span></div><div class="content">1 简介 朴素贝叶斯法（Naive Bayesian Model，NBM）是基于贝叶斯定理与特征条件独立假设的分类方法。
对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率分布；然后基于此模型，对给定的输入，利用贝叶斯定理求出后验概率最大的输出。
朴素贝叶斯方法实现简单，学习与预测的效率都很高，是一种常用方法。
2 贝叶斯定理
已知某条件概率 $P(A|B)$ ，如何得到两个事件交换后的概率 $P(B|A)$ ：
  $P(B|A) = \frac{P(AB)}{P(A)} = \frac{P(A|B)P(B)}{P(A)}$

全概率公式：
  $P(A) = \sum_{i=1}^n P(B_i) P(A|B_i)$


3 朴素贝叶斯定义设训练数据集 $ T=\{(x_1,y_1),(x_2,y_2),…,(x_N,y_N)\} $ 由$P(X,Y)$ 独立同分布产生，其中 $ x_i\in X\subseteq R^n $ 为实例特征向量， $ y_i\in Y=\{c_1,c_2,..,c_k\} $ 为实例类别， $ i=1,2,…,N $ 。
对于新的 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/machine-learning-K-Nearest-Neighbors/" title="【机器学习】k近邻算法">     <img class="post_bg" src="/machine-learning-K-Nearest-Neighbors/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】k近邻算法"></a></div><div class="recent-post-info"><a class="article-title" href="/machine-learning-K-Nearest-Neighbors/" title="【机器学习】k近邻算法">【机器学习】k近邻算法</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-11-27T12:05:35.000Z" title="发表于 2021-11-27 20:05:35">2021-11-27</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine-learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/machine-learning/">machine-learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/knn/">knn</a></span></div><div class="content">1 k近邻算法1.1 算法简介k近邻（K-Nearest Neighbors, KNN）法是一种基本分类与回归方法，支持多分类，于1968年由Cover和Hart提出。

输入：实例的特征空间向量。

输出：实例的类别。

算法思想：分类时，对新的实例，根据其k个最近邻的训练实例的类别，通过多数表决等方式进行预测。k近邻法实际上利用训练数据集对特征向量空间进行划分，并作为其分类的“模型”。

优点：

精度高
对异常值不敏感
无数据输入假定


缺点：
计算复杂度高
空间复杂度高


适用范围：数值型、标称型

k值的选择、距离度量方法及分类决策规则是k近邻法的三个要素。
1.2 算法原理存在一个样本数据集合，也称作训练样本集 $X$ ，并且样本集中每个数据 $x_i$ 都存在标签 $y_i$ ，即样本集中每个数据与所属分类的对应关系。
输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。
一般来说，只选择样本数据集中前N个最相似的数据。k一般不大于20，最后，选择k个中出现次数最多的分类，作为新数据的分类 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://avatars.githubusercontent.com/u/91741133?v=4" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Kevin Parker</div><div class="author-info__description">一只菜鸟的学习笔记</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">26</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">28</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Kairan-Peng"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Kairan-Peng" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:peng.kairan@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/docker/" title="【Docker】入门详解"><img src="/docker/docker.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【Docker】入门详解"/></a><div class="content"><a class="title" href="/docker/" title="【Docker】入门详解">【Docker】入门详解</a><time datetime="2022-02-11T07:05:20.000Z" title="发表于 2022-02-11 15:05:20">2022-02-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/machine-learning-Principal-Components-Analysis/" title="【机器学习】主成分分析"><img src="/machine-learning-Principal-Components-Analysis/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】主成分分析"/></a><div class="content"><a class="title" href="/machine-learning-Principal-Components-Analysis/" title="【机器学习】主成分分析">【机器学习】主成分分析</a><time datetime="2022-01-21T13:57:20.000Z" title="发表于 2022-01-21 21:57:20">2022-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/machine-learning-clustering/" title="【机器学习】聚类方法"><img src="/machine-learning-clustering/machine-learning.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】聚类方法"/></a><div class="content"><a class="title" href="/machine-learning-clustering/" title="【机器学习】聚类方法">【机器学习】聚类方法</a><time datetime="2022-01-18T09:23:00.000Z" title="发表于 2022-01-18 17:23:00">2022-01-18</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/C/"><span class="card-category-list-name">C++</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Docker/"><span class="card-category-list-name">Docker</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/computer-vision/"><span class="card-category-list-name">computer-vision</span><span class="card-category-list-count">5</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/help/"><span class="card-category-list-name">help</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/machine-learning/"><span class="card-category-list-name">machine-learning</span><span class="card-category-list-count">15</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/C/" style="font-size: 1.15em; color: rgb(97, 12, 11)">C++</a><a href="/tags/computer-vision/" style="font-size: 1.38em; color: rgb(21, 168, 43)">computer-vision</a><a href="/tags/exp/" style="font-size: 1.3em; color: rgb(33, 50, 25)">exp</a><a href="/tags/frp/" style="font-size: 1.15em; color: rgb(130, 173, 152)">frp</a><a href="/tags/remote-desktop/" style="font-size: 1.15em; color: rgb(101, 54, 20)">remote-desktop</a><a href="/tags/ssh/" style="font-size: 1.22em; color: rgb(71, 123, 11)">ssh</a><a href="/tags/hello-world/" style="font-size: 1.15em; color: rgb(68, 178, 50)">hello-world</a><a href="/tags/machine-learning/" style="font-size: 1.45em; color: rgb(70, 144, 6)">machine-learning</a><a href="/tags/decision-tree/" style="font-size: 1.22em; color: rgb(95, 65, 45)">decision-tree</a><a href="/tags/knn/" style="font-size: 1.22em; color: rgb(70, 135, 2)">knn</a><a href="/tags/logistic-regression/" style="font-size: 1.22em; color: rgb(117, 195, 121)">logistic-regression</a><a href="/tags/max-entropy-model/" style="font-size: 1.15em; color: rgb(138, 126, 124)">max-entropy-model</a><a href="/tags/unsupervised-learning/" style="font-size: 1.15em; color: rgb(39, 70, 135)">unsupervised-learning</a><a href="/tags/nbm/" style="font-size: 1.15em; color: rgb(33, 144, 51)">nbm</a><a href="/tags/hexo/" style="font-size: 1.15em; color: rgb(102, 199, 56)">hexo</a><a href="/tags/blog/" style="font-size: 1.15em; color: rgb(18, 156, 158)">blog</a><a href="/tags/perceptron/" style="font-size: 1.15em; color: rgb(49, 41, 66)">perceptron</a><a href="/tags/svm/" style="font-size: 1.15em; color: rgb(29, 197, 98)">svm</a><a href="/tags/PCA/" style="font-size: 1.15em; color: rgb(175, 62, 162)">PCA</a><a href="/tags/clustering/" style="font-size: 1.15em; color: rgb(111, 195, 109)">clustering</a><a href="/tags/experiment/" style="font-size: 1.3em; color: rgb(193, 32, 135)">experiment</a><a href="/tags/bagging/" style="font-size: 1.15em; color: rgb(156, 139, 168)">bagging</a><a href="/tags/boosting/" style="font-size: 1.15em; color: rgb(168, 52, 106)">boosting</a><a href="/tags/random-forest/" style="font-size: 1.15em; color: rgb(55, 84, 110)">random-forest</a><a href="/tags/adaboost/" style="font-size: 1.15em; color: rgb(73, 19, 107)">adaboost</a><a href="/tags/xgboost/" style="font-size: 1.15em; color: rgb(173, 68, 26)">xgboost</a><a href="/tags/lgbm/" style="font-size: 1.15em; color: rgb(99, 39, 115)">lgbm</a><a href="/tags/Docker/" style="font-size: 1.15em; color: rgb(200, 28, 144)">Docker</a></div></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">26</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-02-27T12:55:52.900Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Kevin Parker</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="icp"><a target="_blank" rel="noopener" href="http://beian.miit.gov.cn/"><span>浙ICP备2021037349号-1</span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    var typed = new Typed("#subtitle", {
      strings: "记得你上次打开这个博客,还是在上次".split(","),
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '记得你上次打开这个博客'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>